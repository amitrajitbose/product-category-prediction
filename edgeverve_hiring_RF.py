# -*- coding: utf-8 -*-
"""Edgeverve_Hiring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kIckpFU6QJZnCG2WwWewHG3lBURh0QvL

# The Great Indian Data Scientist Hiring Challenge

### Author: Amitrajit Bose
- [Mail Me](amitrajitbose9@gmail.com)
- [Connect](https://linkedin.com/in/amitrajitbose)
- [More](https://amitrajitbose.github.io/)
- [Github](https://github.com/amitrajitbose)

<p align="right">
  <img src="https://amitrajitbose.github.io/img/profile.jpg">
</p>
"""

from google.colab import files
#files.upload()

#!unzip 88b2c062-9-Dataset.zip
!ls

import numpy as np
import pandas as pd

df = pd.read_csv('Dataset/Train.csv')
dftest = pd.read_csv('Dataset/Test.csv')
dfsample = pd.read_csv('Dataset/sample_submission.csv')
df.head()

import nltk, string
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')
from nltk.stem.porter import PorterStemmer
porter = PorterStemmer()
from nltk.corpus import stopwords

def get_tokens(s: str) -> list:
  """
  Tokenizes a name string and returns the list of tokens
  """
  table = str.maketrans(
      string.punctuation, ' '*len(string.punctuation))
  s = s.lower().translate(table)
  tokens = [w for w in s.split() if w.isalpha()]
  return tokens

def text_preprocess(text):
  """
  Preprocess a string by removing punctuations,
  stopwords, stemming the tokens, etc. Returns a
  space separated string.
  """
  tokens = get_tokens(text)
  tokens = [x.lower() for x in tokens]
  table = str.maketrans(' ', ' ', string.punctuation)
  stripped = [w.translate(table) for w in tokens]
  # remove remaining tokens that are not alphabetic
  words = [word for word in stripped if word.isalpha()]
  stop_words = set(stopwords.words('english'))
  words = [porter.stem(w) for w in words if not w in stop_words]
  return ' '.join(words)

df['text'] = df.apply(lambda x: text_preprocess(x['Item_Description']), axis=1)
df.head()

import sklearn
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(min_df=5, norm='l2', ngram_range=(1, 2), stop_words='english')
vectorizer.fit(df.text.tolist())

#df['text_vector'] = df.apply(lambda x: vectorizer.transform(x['text'].split()), axis=1)
text_features = vectorizer.fit_transform(df.text).toarray()
labels = df.Product_Category

one_hot_labels = list(set(labels))

def encode_labels(lab,one_hot_labels):
  return one_hot_labels.index(lab)

from tqdm import tqdm_notebook as tqdm
newlabels = []
for i in tqdm(labels):
  newlabels.append(encode_labels(i, one_hot_labels))

features = text_features.tolist()

maxamt = max(df.Inv_Amt)
minamt = min(df.Inv_Amt)
k = 0
for i in tqdm(df.Inv_Amt):
  scaled = (i-minamt)/(maxamt-minamt)
  features[k].insert(0,scaled)
  k += 1
print(len(features),'X',len(features[0]))

print("Feature Vector Shape: ", len(features[0]))

featuresfinal = np.array(features)
labelsfinal = np.array(newlabels)

def reverse_encode(i, one_hot):
  return one_hot[i]

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(featuresfinal, labelsfinal, test_size=0.2, random_state=42)

X_train.shape, X_test.shape, Y_train.shape, Y_test.shape

"""## Model Selection"""

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import cross_val_score
from matplotlib import pyplot as plt

models = [
    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),
    LinearSVC(),
    MultinomialNB(),
    LogisticRegression(random_state=0),
]
CV = 5
cv_df = pd.DataFrame(index=range(CV * len(models)))
entries = []
for model in models:
  model_name = model.__class__.__name__
  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)
  for fold_idx, accuracy in enumerate(accuracies):
    entries.append((model_name, fold_idx, accuracy))

cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])

import seaborn as sns
sns.boxplot(x='model_name', y='accuracy', data=cv_df)
sns.stripplot(x='model_name', y='accuracy', data=cv_df, 
              size=8, jitter=True, edgecolor="gray", linewidth=2)
plt.show()

cv_df.groupby('model_name').accuracy.mean()

"""## Model Evaluation"""

model = RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0)
X_train, X_test, Y_train, Y_test, indices_train, indices_test = train_test_split(featuresfinal, labelsfinal, df.index, test_size=0.2, random_state=42)
model.fit(X_train, Y_train)
Y_pred = model.predict(X_test)

from sklearn.metrics import confusion_matrix
conf_mat = confusion_matrix(Y_test, Y_pred)

fig, ax = plt.subplots(figsize=(6,6))
sns.heatmap(conf_mat, annot=True, fmt='d')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()
print("Train: ", model.score(X_train, Y_train))
print("Test: ",model.score(X_test, Y_test))

"""## Generate Test CSV"""

idx = []
category = []
for i in tqdm(dftest.itertuples()):
  idx.append(i.Inv_Id)
  text = i.Item_Description
  f = vectorizer.transform([text]).toarray().tolist()
  f[0].insert(0,i.Inv_Amt)
  x = model.predict(f)[0]
  category.append(reverse_encode(x, one_hot_labels))

print(len(idx), len(category))

submit = pd.DataFrame({'Inv_Id':idx, 'Product_Category':category})
submit.head()

submit.to_csv('./submitRF.csv', index=0)

files.download('submitRF.csv')